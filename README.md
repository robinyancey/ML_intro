# ML_intro


----------------------------------------------------------------------
Python Review
----------------------------------------------------------------------
Data Cleaning and Prep Intro
----------------------------------------------------------------------
----------------------------------------------------------------------
Unsupervised Learning ML intro 
----------------------------------------------------------------------
1. Unsupervised Learning vs supervised learning (definitions and major applications of each/examples)
2. Categories of unsupervised Learning
3. Problems Encountered in Unsupervised Learning
4. Data Processing and Scaling
5. Preprocessing Methods (pandas)
6. Using Data Transforms
7. Dimensionality Reduction in Unsupervised Learning
8. Clustering, k-Means Clustering
9. Agglomerative Clustering
10. DBSCAN

----------------------------------------------------------------------
Pandas and NumPy intro
----------------------------------------------------------------------
1. Introduction to Pandas and NumPy
2. Loading Data into Pandas
3. First Steps After Loading Data
4. Categorical vs. Continuous Features
5. Regression vs. Classification
6. Exploratory Data Analysis (EDA)
7. Transforming Data Features
8. Extracting and Selecting Features
9. Feature Construction and Encoding
10. Working with Real Datasets
11. Unbalanced and Dirty Data
12. Regression and k-NN Examples
13. Generalization, Overfitting, and Model Complexity

----------------------------------------------------------------------
KNN
----------------------------------------------------------------------
1. Loading Data into Pandas
2. Understanding and Examination of Data Set
3. Data Preprocessing
4. Target Column Outcomes
5. Obtaining Numerical Features from Categorical Columns
6. Mapping of Ordinal Features
7. Construction Features
8. Regression
9. Generalization, Overfitting, and Underfitting
10. Model Complexity and Dataset Size
11. k-Nearest Neighbors (Regression)
12. k-Nearest Neighbors (Classification)

----------------------------------------------------------------------
Linear Models
----------------------------------------------------------------------
1. Linear Regression
2. Ridge Regression
3. Lasso Paths
4. Linear Classification Algorithms
5. Logistic Regression
6. Criterion for Optimality
7. Visualization in Matplotlib: ROC and PR Curves

----------------------------------------------------------------------
PCA
----------------------------------------------------------------------
1. Introduction to PCA
2. Mathematical Foundations of PCA
3. Why Use PCA? Practical Motivations
4. Data Preparation for PCA
5. PCA on Real-World Data
6. Visualizing PCA Results
7. Choosing the Number of Components
8. Reconstruction and Information Loss
9. PCA for Visualization: 2D and 3D Plots
10. Limitations, Pitfalls, and Best Practices

----------------------------------------------------------------------
Decision trees & Naive bayes
----------------------------------------------------------------------
1. Introduction to Decision Trees
2. Criterion for Optimality
3. Decision Tree for Classification
4. Decision Tree for Regression
5. Pruning and Overfitting
6. Feature Importance and Diagnostics
7. Attribute Selection Techniques
8. Fine Tuning and Embeddings
9. Introduction to Naive Bayes
10. Naive Bayes for Classification
11. Comparison and Practical Tips

----------------------------------------------------------------------
Ensemble methods: Random forest, bagging, boosting
----------------------------------------------------------------------
1. Introduction to Ensemble Methods
2. Bias-Variance Tradeoff
3. Bagging (Bootstrap Aggregation)
    - Intuition & Theory
    - Mathematical Formulation
    - Algorithm Steps
    - Example: Soil pH Regression
    - Visualizing Bagging
4. Random Forests
    - Intuition & Theory
    - Mathematical Formulation
    - Algorithm Steps
    - Example: Soil pH Regression
    - Feature Importance & Visualization
    - Practical Tips & Pitfalls
5. Boosting
    - AdaBoost: Intuition, Theory, and Example
    - Gradient Boosting: Intuition, Theory, and Example
    - Histogram-based Boosting
    - Visualizing Boosting
    - Practical Tips & Pitfalls
6. Hyperparameter Tuning & Parallelization

----------------------------------------------------------------------
SVM
----------------------------------------------------------------------
1. Introduction to Support Vector Machines
2. Linear SVM for Classification
3. Nonlinear SVM and the Kernel Trick
4. SVM for Regression (SVR)
5. Hyperparameter Tuning and Model Selection
6. Model Evaluation and Visualization
7. SVM from Scratch with Scipy

----------------------------------------------------------------------
CNN Deep Learning Intro (just for fun, intro to ENGR 011)
----------------------------------------------------------------------

* ML homework will be sent as Google Drive links through announcements in Canvas.
